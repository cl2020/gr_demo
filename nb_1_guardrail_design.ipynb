{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKAoBOXwdlx"
      },
      "source": [
        "# Guardrails Design\n",
        "**Colin @ 2025-03**\n",
        "\n",
        "This notebook explains the creation of guardrails in an RAG flow for a credit card chatbot:\n",
        "\n",
        "- Understand the RAG process and what could go wrong (WCGW)\n",
        "- Identify risks and define corresponding mitigations (guardrails)\n",
        "- Focus on groundedness/hallucination validation with additional guardrails aligned with best practices and cloud providers (e.g. AWS)\n",
        "- Outline qualitative and quantitative measures for evaluating guardrail's effectiveness\n",
        "- Discuss fine-tuning strategies for continuous improvement\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## README Before You Start\n",
        "\n",
        "1. Tested on MacBook M1 Pro (32GB RAM, Python 3.10) and Google Colab.\n",
        "2. Recommended to run in **Google Colab**:\n",
        "   - Default runtime is sufficient (no Colab Pro or GPU needed).\n",
        "   - Good to have a GPU (faster)\n",
        "3. To run locally (not recommended), ensure:\n",
        "   - Python 3.10+\n",
        "   - Access to `pip install`\n",
        "   - Permission to download LLMs from Hugging Face\n",
        "   - Jupyter Notebook/Lab installed, or `ipykernel` for running notebooks in VSCode"
      ],
      "metadata": {
        "id": "D2vmZBxOzlHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env TOKENIZERS_PARALLELISM=true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tORwEzblxXFo",
        "outputId": "2ef72a3f-3d53-4d50-98df-cf3734cf51a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UPnS-GR3wdly"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install guardrails-ai\n",
        "!pip install presidio_analyzer\n",
        "!pip install presidio_anonymizer\n",
        "!pip install sentence_transformers\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4pNZ_uNwdlz"
      },
      "source": [
        "# Load All Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v0zS3kMFwdl0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import re\n",
        "import json\n",
        "import logging\n",
        "from guardrails import validator_base\n",
        "from guardrails.validator_base import (\n",
        "    Validator,\n",
        "    register_validator,\n",
        "    FailResult,\n",
        "    PassResult,\n",
        "    ValidationResult)\n",
        "from transformers import pipeline\n",
        "from typing import Any, Dict, List, Optional\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "logging.getLogger(\"presidio-analyzer\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkK0g_QBwdl0"
      },
      "source": [
        "# Load All Required LLMs for Guardrails\n",
        "- Ensure all LLMs are downloaded from Hugging Face without errors.\n",
        "- This step might take a while to complete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b_WkHnG0wdl0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Hallucination Detection\n",
        "nli_model_1 = pipeline(\n",
        "    \"text-classification\", model='GuardrailsAI/finetuned_nli_provenance')\n",
        "\n",
        "# Topic Classification\n",
        "topic_model = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model='facebook/bart-large-mnli',\n",
        "    hypothesis_template=\"This sentence above contains discussions of the folllowing topics: {}.\",\n",
        "    multi_label=True)\n",
        "\n",
        "# English Langauge Detection\n",
        "lan_class_model = pipeline(\n",
        "    \"text-classification\", model=\"qanastek/51-languages-classifier\")\n",
        "\n",
        "# Toxic Language Detection\n",
        "toxicity_model = pipeline(\n",
        "    \"text-classification\", model=\"JungleLee/bert-toxic-comment-classification\")\n",
        "\n",
        "# PII Detection and Anonymisation\n",
        "logging.getLogger(\"presidio-analyzer\").setLevel(logging.ERROR)\n",
        "analyzer = AnalyzerEngine()\n",
        "anonymizer= AnonymizerEngine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwv4o_z-wdl1"
      },
      "source": [
        "# Define Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8aeVo1ktwdl1"
      },
      "outputs": [],
      "source": [
        "def get_result(result, verbose=True):\n",
        "    \"\"\"\n",
        "    Extracts validation result details. Converts the result object into a\n",
        "    dictionary with relevant fields depending on the outcome.\n",
        "    - If the outcome is 'pass', it loads and includes the value override.\n",
        "    - If the outcome is 'fail', it loads the error message and adds the fix\n",
        "      response.\n",
        "\n",
        "    Args:\n",
        "        result: A ValidationResult object with outcome, value_override,\n",
        "                error_message, and fix_value.\n",
        "        verbose (bool): Whether to print result details to the console.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the outcome and relevant details.\n",
        "    \"\"\"\n",
        "    outcome = result.outcome\n",
        "    output = {'outcome':outcome}\n",
        "    if outcome=='pass':\n",
        "        details = json.loads(result.value_override)\n",
        "        output.update(details)\n",
        "        if verbose:\n",
        "            print(f'Validation Result: {outcome}, Details: {details}')\n",
        "    elif outcome=='fail':\n",
        "        details = json.loads(result.error_message)\n",
        "        output.update(details)\n",
        "        output['response'] = result.fix_value\n",
        "        if verbose:\n",
        "            print(f'Validation Result: {outcome}, Details: {details}, '\n",
        "                  f'Bot Reponse: {result.fix_value}')\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What Could Go Wrong (WCGW) and Associated Risks\n",
        "\n",
        "- Chatbot Output:\n",
        "    - **WCGW #1**: Irrelevant or incorrect answers (hallucination)\n",
        "    - **WCGW #2**: Toxic or abusive responses\n",
        "\n",
        "- User Input:\n",
        "    - **WCGW #3**: Non-English questions\n",
        "    - **WCGW #4**: Unsupported topics\n",
        "    - **WCGW #5**: Competitor mentions\n",
        "    - **WCGW #6**: Submission of personal or sensitive information\n",
        "\n",
        "- Associated Risks:\n",
        "    - Poor user experience if the knowledge base isn't multilingual\n",
        "    - Reputational damage and customer complaints\n",
        "    - Regulatory or legal consequences\n",
        "    - Breach of conduct standards\n",
        "    - Malicious use, increased API costs\n",
        "    - Privacy violations or compliance issues\n"
      ],
      "metadata": {
        "id": "vOIqzv0V4Qnm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHMKhE-twdl2"
      },
      "source": [
        "# Guard Chatbot Output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Guardrail for Hallucination\n",
        "\n",
        "- **Relevant WCGW**: #1 — Irrelevant or incorrect answers  \n",
        "- **Mitigation**: Use an NLI model to check if responses are grounded in retrieved context.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Treat response as *hypothesis*, context as *premise* using an NLI model.  \n",
        "  - Output: *entailment* (grounded), *contradiction* (conflicts), *neutral*.  \n",
        "\n",
        "- **Limitations**:  \n",
        "  - Only checks against retrieved context  \n",
        "  - False positives possible\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: entailment / neutral / contradiction  \n",
        "  - *Quantitative*: Confidence score\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Try other NLI or GenAI models  \n",
        "  - Tune threshold with labelled data  \n",
        "  - Sentence-level check (costly)\n"
      ],
      "metadata": {
        "id": "bS-mlN-58NHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gZxANJOewdl2"
      },
      "outputs": [],
      "source": [
        "@register_validator(name=\"hullucination\", data_type=\"string\")\n",
        "class HallucinationGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator that detects hallucinations in model-generated text by\n",
        "    comparing it with a reference premise using a natural language inference\n",
        "    (NLI) model. The validator uses the model's output to assess whether the\n",
        "    generated text is entailed by, neutral to, or contradicts the premise.\n",
        "\n",
        "    - If the output is 'entailment' or 'neutral', it passes the validation.\n",
        "    - If it's 'contradiction' but the confidence score is below a threshold,\n",
        "      it is considered neutral and passes.\n",
        "    - Otherwise, the validation fails with an error message.\n",
        "\n",
        "    Attributes:\n",
        "        model: A callable NLI model that takes a dict with \"text\"\n",
        "               and \"text_pair\".\n",
        "        threshold (str): The maximum score at which a contradiction is treated\n",
        "                         as neutral.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, threshold:str, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "        self.threshold=threshold\n",
        "\n",
        "    def _validate(self, value: str, premise: str):\n",
        "        self.premise = premise\n",
        "        result = self.model({\"text\": self.premise, \"text_pair\": value})\n",
        "        label = result['label'].lower()\n",
        "        score = result['score']\n",
        "\n",
        "        if label==\"entailment\":\n",
        "            return PassResult(value_override=json.dumps(result))\n",
        "\n",
        "        # Note: The NLI used by this demo does not return neutral label\n",
        "        elif label==\"neutral\":\n",
        "            return PassResult(value_override=json.dumps(result))\n",
        "        elif label==\"contradiction\" and score<self.threshold:\n",
        "            return PassResult(\n",
        "                value_override=json.dumps({\"label\":\"neutral\",\"score\":score}))\n",
        "        else:\n",
        "            return FailResult(\n",
        "                error_message=json.dumps(result),\n",
        "                fix_value=\"I'm sorry, I couldn't find enough information \"\n",
        "                          \"to answer that accurately.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1nT8YG8wdl2"
      },
      "source": [
        "### 1.1 Test and Demo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieved context (example)\n",
        "premise = \"\"\"\\\n",
        "Context: Earn 25,000 CommBank Awards points or 17,500 Qantas Points\n",
        "each month when you spend $3,000 or more per month for the first 4 months\n",
        "on a new Ultimate Awards credit card.\n",
        "\"\"\"\n",
        "# Bot reponse (example)\n",
        "hypothesis_1 = \"\"\"\\\n",
        "You would be eligible to earn 25,000 award points or\n",
        "17,500 Qantas points each month when you spend $3,000 or more on a new\n",
        "Ultimate Awards credit card within the first 4 months.\n",
        "\"\"\"\n",
        "hypothesis_2 = \"\"\"\\\n",
        "Answer: Yes, you might get those points.\n",
        "\"\"\"\n",
        "\n",
        "# Instantiation\n",
        "hallucination_gr = HallucinationGuardrail(model=nli_model_1, threshold=0)\n",
        "\n",
        "# Demo\n",
        "demo_1 = hallucination_gr._validate(hypothesis_1, premise)\n",
        "demo_2 = hallucination_gr._validate(hypothesis_2, premise)\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo_1)\n",
        "_ = get_result(demo_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WueThflVRRcQ",
        "outputId": "4dc31164-6894-408b-ca10-629cc8b3c824"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: pass, Details: {'label': 'entailment', 'score': 0.8769131302833557}\n",
            "Validation Result: fail, Details: {'label': 'contradiction', 'score': 0.8570698499679565}, Bot Reponse: I'm sorry, I couldn't find enough information to answer that accurately.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjdTA5olwdl2"
      },
      "source": [
        "### 1.2 Fine-tuning Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5zLm6H8wdl3",
        "outputId": "25bc0626-99f3-458a-dda0-9da1343c679c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: pass, Details: {'label': 'neutral', 'score': 0.8570698499679565}\n"
          ]
        }
      ],
      "source": [
        "# Instantiation\n",
        "hallucination_gr = HallucinationGuardrail(model=nli_model_1, threshold=.86)\n",
        "\n",
        "# Demo\n",
        "demo_2 = hallucination_gr._validate(hypothesis_2, premise)\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7lpgxI5wdl3"
      },
      "source": [
        "## 2 Guardrail for Toxicity\n",
        "\n",
        "- **Relevant WCGW**: #2 — Toxic or abusive responses  \n",
        "- **Mitigation**: Use a fine-tuned BERT-based classifier to detect and block toxic content.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Classify user input using a toxicity detection model (binary).  \n",
        "  - If toxicity, suppress response and return a predefined message.\n",
        "\n",
        "- **Limitations**:  \n",
        "  - May miss subtle or sarcastic toxicity  \n",
        "  - False positives possible\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: toxic / not toxic  \n",
        "  - *Quantitative*: Confidence score\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Adjust threshold to balance sensitivity and false positives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1oLEHv3jwdl3"
      },
      "outputs": [],
      "source": [
        "@register_validator(name=\"toxicity\", data_type=\"string\")\n",
        "class ToxicityGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator to detect toxic language using a text classification\n",
        "    model. The validator assesses if the input is toxic based on the model's\n",
        "    label and score, and applies a configurable threshold to determine the\n",
        "    outcome.\n",
        "\n",
        "    - If the input is labeled as 'non-toxic', it passes.\n",
        "    - If labeled as 'toxic' and no threshold is provided, or the score exceeds\n",
        "      the threshold, it fails.\n",
        "    - If the toxicity score is below the threshold, it passes, treating the\n",
        "      message as 'non-toxic'.\n",
        "\n",
        "    Attributes:\n",
        "        model: A callable classification model returning a list with 'label'\n",
        "               and 'score'.\n",
        "        threshold (float, optional): A score threshold below which 'toxic'\n",
        "                                     inputs are treated as non-toxic.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, threshold:float=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def _validate(self, value: str):\n",
        "        result = self.model(value)[0]\n",
        "        label = result['label']\n",
        "        score = result['score']\n",
        "        if label=='non-toxic':\n",
        "            return PassResult(value_override=json.dumps(result))\n",
        "\n",
        "        elif (label=='toxic' and self.threshold is None) or (\n",
        "              label=='toxic' and self.threshold < score):\n",
        "            return FailResult(\n",
        "                error_message=json.dumps(result),\n",
        "                fix_value=\"I can't continue the conversation if inappropriate \"\n",
        "                          \"language is used. Let me know how I can help \"\n",
        "                          \"respectfully.\")\n",
        "\n",
        "        elif label=='toxic' and score<self.threshold:\n",
        "            return PassResult(\n",
        "                value_override=json.dumps({'label':'non-toxic', 'score':score}))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Test and Demo"
      ],
      "metadata": {
        "id": "zcGNkVZ7Brqw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vpDPGcFwdl3",
        "outputId": "41d1d75a-5175-43c3-b119-a2a821e67746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: fail, Details: {'label': 'toxic', 'score': 0.9992153644561768}, Bot Reponse: I can't continue the conversation if inappropriate language is used. Let me know how I can help respectfully.\n",
            "Validation Result: pass, Details: {'label': 'non-toxic', 'score': 0.999581515789032}\n"
          ]
        }
      ],
      "source": [
        "# Instantiation\n",
        "toxicity_gr = ToxicityGuardrail(model=toxicity_model)\n",
        "\n",
        "# Demo\n",
        "demo_1 = toxicity_gr._validate(\"Sorry, I cannot find any context about\"\n",
        "                               \"`shitty service`.\")\n",
        "demo_2 = toxicity_gr._validate(\"Sorry, I cannot give an answer.\")\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo_1)\n",
        "_ = get_result(demo_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDbiTKNawdl3"
      },
      "source": [
        "# Guard User Input (Additional Guardrails)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAh4guZwdl3"
      },
      "source": [
        "## 3 Guardrail for Non-English User Input\n",
        "\n",
        "- **Relevant WCGW**: #3 — User's question is not in English  \n",
        "- **Mitigation**: Detect and handle non-English queries to ensure consistent chatbot performance.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Use an XLM-RoBERTa-based model for multilingual language detection.  \n",
        "  - If input is not English, block the request and prompt the user to switch to English.\n",
        "\n",
        "- **Limitations**:  \n",
        "  - May misclassify short or mixed-language inputs  \n",
        "  - Limited support for informal expressions\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: Detected language label  \n",
        "  - *Quantitative*: Confidence score\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Adjust confidence threshold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lEcEzw0Kwdl3"
      },
      "outputs": [],
      "source": [
        "@register_validator(name=\"english_input\", data_type=\"string\")\n",
        "class EnglishInputGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator to check if the input text is in English. It uses a\n",
        "    language detection model and validates based on the predicted language.\n",
        "\n",
        "    - If the input is in English ('en-US'), validation passes.\n",
        "    - If the input is in another language, validation fails.\n",
        "\n",
        "    Attributes:\n",
        "        model: A language detection model that returns 'label' and 'score'.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.model = model\n",
        "\n",
        "    def _validate(self, value: str):\n",
        "        result = self.model(value)[0]\n",
        "        label = result['label']\n",
        "        score = result['score']\n",
        "        if label=='en-US':\n",
        "            return PassResult(value_override=json.dumps(result))\n",
        "        else:\n",
        "            return FailResult(\n",
        "                error_message=json.dumps(result),\n",
        "                fix_value=\"Oops! I’m still learning new languages. But for now\"\n",
        "                          \", I can only chat confidently in English.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Test and Demo"
      ],
      "metadata": {
        "id": "shStkTtNDkTs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2dt2tIjwdl3",
        "outputId": "269fef30-3271-4354-c1ec-42da91639efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: fail, Details: {'label': 'zh-CN', 'score': 0.9999196529388428}, Bot Reponse: Oops! I’m still learning new languages. But for now, I can only chat confidently in English.\n",
            "Validation Result: pass, Details: {'label': 'en-US', 'score': 0.9999409914016724}\n"
          ]
        }
      ],
      "source": [
        "# Instantiation\n",
        "english_gr = EnglishInputGuardrail(model=lan_class_model)\n",
        "\n",
        "# Demo\n",
        "demo1 = english_gr._validate(\"我想知道我每花1澳币能赚多少ultimate awards积分?\")\n",
        "demo2 = english_gr._validate(\"How much points do I earn from every 1 dollar I \"\n",
        "                             \"spend?\")\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo1)\n",
        "_ = get_result(demo2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alOp4CyOwdl3"
      },
      "source": [
        "## 4 Guardrail for Topic Filtering\n",
        "\n",
        "- **Relevant WCGW**: #4 — User's question relates to topics not supported by the bot  \n",
        "- **Mitigation**: Use a zero-shot classification model to detect whether input relates to allowed or banned topics.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Classify user input using zero-shot classification.  \n",
        "  - If the topic is allowed, pass the input to the chatbot.  \n",
        "  - If the topic is banned, block the input and return a predefined message.  \n",
        "\n",
        "- **Limitations**:  \n",
        "  - Zero-shot model may misclassify\n",
        "  - Manual curation of topic labels and keywords required\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: Topic labels\n",
        "  - *Quantitative*: Confidence scores\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Experiment with different models or keyword strategies  \n",
        "  - Optimise thresholds and topic definitions based on real input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HmBxP6aHwdl4"
      },
      "outputs": [],
      "source": [
        "@register_validator(name=\"topic\", data_type=\"string\")\n",
        "class TopicGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator to check whether the input text belongs to an allowed\n",
        "    or banned topic. It uses a classification model to label the input and\n",
        "    validates based on topic lists.\n",
        "\n",
        "    - If the topic is banned, validation fails with a fixed response.\n",
        "    - If the topic is allowed, validation passes.\n",
        "    - If the topic is unknown, validation fails.\n",
        "\n",
        "    Attributes:\n",
        "        model: A classification model returning 'labels' and 'scores'.\n",
        "        allowed_topics (list): Topics that are permitted.\n",
        "        banned_topics (list): Topics that are restricted.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, allowed_topics, banned_topics, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.allowed_topics = allowed_topics\n",
        "        self.banned_topics = banned_topics\n",
        "        self.model = model\n",
        "\n",
        "    def _validate(self, value: str):\n",
        "        result = self.model(value, self.allowed_topics+self.banned_topics)\n",
        "        label = result['labels'][0]\n",
        "        top_result = {'label': label, 'score':result['scores'][0]}\n",
        "\n",
        "        if label in self.banned_topics:\n",
        "            return FailResult(\n",
        "                error_message=json.dumps(top_result),\n",
        "                fix_value=\"Let's keep it focused on credit cards. \"\n",
        "                          \"Happy to help with anything in that space!\")\n",
        "        elif label in self.allowed_topics:\n",
        "            return PassResult(value_override=json.dumps(top_result))\n",
        "        else:\n",
        "            return FailResult(\n",
        "                error_message=json.dumps(top_result),\n",
        "                fix_value=\"Let's keep it focused on credit cards. \"\n",
        "                          \"Happy to help with anything in that space!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Test and Demo"
      ],
      "metadata": {
        "id": "Ja-Mwe13G6BX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_0Jmyqrwdl4",
        "outputId": "1d0e5aa4-dec3-429e-a695-2ea6e2892c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: fail, Details: {'label': 'joke', 'score': 0.9411715269088745}, Bot Reponse: Let's keep it focused on credit cards. Happy to help with anything in that space!\n",
            "Validation Result: pass, Details: {'label': 'awards points', 'score': 0.9510924816131592}\n"
          ]
        }
      ],
      "source": [
        "# Scope\n",
        "allowed_topics = [\n",
        "    \"credit card\", \"ultimate awards\", \"annual fees\", \"credit limit\",\n",
        "    \"minimum repayment\", \"interest rates\", \"interest-free days\",\n",
        "    \"monthly fees\", \"cash advance fees\", \"late payment fees\",\n",
        "    \"awards points\", \"qantas points\", \"earning points\",\n",
        "    \"points offers\", \"cashback offers\", \"redeeming points\",\n",
        "    \"international transaction fee\", \"travel insurance\"]\n",
        "\n",
        "banned_topics = [\n",
        "    \"home loan\", \"mortgage\", \"personal loan\", \"savings account\",\n",
        "    \"term deposit\", \"transaction account\", \"offset account\", \"insurance\",\n",
        "    \"superannuation\", \"business account\", \"investments\",\n",
        "    \"financial advice\", \"investment advice\", \"complaint\", \"refund\",\n",
        "    \"scam\", \"fraud\", \"password\", \"update personal details\", \"speak to manager\",\n",
        "    \"account locked\", \"privacy\", \"data breach\", \"legal\", \"lawsuit\",\n",
        "    \"joke\", \"preference\", \"pizza\", \"weather\", \"news\", \"sports\", \"religion\",\n",
        "    \"politics\", \"ethics\", \"opinion\"]\n",
        "\n",
        "# Instantiation\n",
        "topic_gr = TopicGuardrail(model=topic_model,\n",
        "                          allowed_topics=allowed_topics,\n",
        "                          banned_topics=banned_topics)\n",
        "\n",
        "# Demo\n",
        "demo_1 = topic_gr._validate(\"Tell me a joke\")\n",
        "demo_2 = topic_gr._validate(\"I want to know more about my award points\")\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo_1)\n",
        "_ = get_result(demo_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEiI4Bewdl4"
      },
      "source": [
        "## 5 Guardrail for Competitor Mentions\n",
        "\n",
        "- **Relevant WCGW**: #4 — Competitor mentions\n",
        "- **Mitigation**: Detect competitor mentions and suppress responses to avoid opinion or comparative information.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Use keyword or `regex` matching to identify competitor names in user input.  \n",
        "  - If a competitor is mentioned, block the query and return a standard response.\n",
        "\n",
        "- **Limitations**:  \n",
        "  - Requires ongoing maintenance of competitor keyword list  \n",
        "  - May misclassify unrelated mentions or miss indirect references\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: Detected competitor mentions\n",
        "  - *Quantitative*: Confidence scores\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Refine keyword list or retrain model as competitors or naming patterns evolve  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@register_validator(name=\"competitor\", data_type=\"string\")\n",
        "class CompetitorGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator to detect mentions of competitors in user input.\n",
        "    It uses regex pattern matching to search for competitor names and\n",
        "    brands in the text.\n",
        "\n",
        "    - If a competitor name is found, validation fails.\n",
        "    - If no match is found, validation passes.\n",
        "\n",
        "    Attributes:\n",
        "        competitors (dict): A dictionary mapping competitor names to their\n",
        "                            associated brand names.\n",
        "    \"\"\"\n",
        "    def __init__(self, competitors:Dict[str, str], **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.competitors=competitors\n",
        "\n",
        "    def _validate(self, value: str):\n",
        "        pattern = re.compile(\n",
        "            r'\\b(' + '|'.join(\n",
        "                re.escape(name) for name in \\\n",
        "                    list(self.competitors.keys()) + \\\n",
        "                    list(self.competitors.values())) + r')\\b',\n",
        "            flags=re.IGNORECASE\n",
        "        )\n",
        "        matches = pattern.findall(value)\n",
        "        if matches:\n",
        "            return FailResult(\n",
        "                error_message=json.dumps({\n",
        "                    'label':matches, 'score':[1.00]*len(matches)}),\n",
        "                fix_value=\"I'm here to help with questions about our products \"\n",
        "                          \"only, so I can't comment on other institutions.\")\n",
        "        else:\n",
        "            return PassResult(\n",
        "                value_override=json.dumps({'label':['no-matches'], 'score':[1.00]}))"
      ],
      "metadata": {
        "id": "BhbQ5qHpOq0W"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1 Test and Demo"
      ],
      "metadata": {
        "id": "TWJqTgyuJVpj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYSgzbTFwdl4",
        "outputId": "d84ba40d-0454-41b4-a97e-aae6a51daa77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: fail, Details: {'label': ['anz', 'amex', 'westpac'], 'score': [1.0, 1.0, 1.0]}, Bot Reponse: I'm here to help with questions about our products only, so I can't comment on other institutions.\n"
          ]
        }
      ],
      "source": [
        "# Scope\n",
        "competitors_dict = {\n",
        "    \"ANZ\": \"ANZ\", \"Westpac\": \"Westpac\", \"NAB\": \"National Australia Bank\",\n",
        "    \"Macquarie\": \"Macquarie Bank\", \"Amex\": \"American Express\",\n",
        "    \"Afterpay\": \"Afterpay\"}\n",
        "\n",
        "# Instantiation\n",
        "competitors_gr = CompetitorGuardrail(competitors=competitors_dict)\n",
        "\n",
        "# Demo\n",
        "demo_1 = competitors_gr._validate(\"Does anz, amex or westpac offer better \"\n",
        "                                  \"credit card with more benefits?\")\n",
        "demo_2 = competitors_gr._validate(\"How much do i need to pay for each \"\n",
        "                                  \"international transaction?\")\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqCFGiMlwdl4"
      },
      "source": [
        "## 6 Guardrail for PII Detection\n",
        "\n",
        "- **Relevant WCGW**: #6 — User submits personal or sensitive information  \n",
        "- **Mitigation**: Detect PII to protect privacy and ensure compliance.\n",
        "\n",
        "- **Approach**:  \n",
        "  - Use Microsoft Presidio to identify PII via pattern matching and NLP.  \n",
        "  - If detected, return a prompt asking the user to revise their input.\n",
        "\n",
        "- **Limitations**:  \n",
        "  - False positives on short or numeric inputs  \n",
        "  - May need custom recognisers for domain-specific PII\n",
        "\n",
        "- **Assessment**:  \n",
        "  - *Qualitative*: Detected entity types\n",
        "  - *Quantitative*: Confidence scores\n",
        "\n",
        "- **Fine-tuning**:  \n",
        "  - Add custom recognisers\n",
        "  - Optionally generate redacted queries for chatbot use\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@register_validator(name=\"PII\", data_type=\"string\")\n",
        "class PIIGuardrail(Validator):\n",
        "    \"\"\"\n",
        "    A custom validator to detect and handle personally identifiable\n",
        "    information (PII) in user input. It uses an analyzer to identify PII\n",
        "    entities and an anonymizer to optionally mask them.\n",
        "\n",
        "    - If PII is detected, validation fails and returns a privacy warning.\n",
        "    - If no PII is found, validation passes.\n",
        "\n",
        "    Attributes:\n",
        "        analyzer: A PII analyzer that identifies entity types in text.\n",
        "        anonymizer: A tool that can anonymize detected PII.\n",
        "        pii_entities (list, optional): Specific PII entities to scan for.\n",
        "    \"\"\"\n",
        "    def __init__(self, analyzer, anonymizer, pii_entities:List[str]=None,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.analyzer = analyzer\n",
        "        self.pii_entities=pii_entities\n",
        "        self.anonymizer = anonymizer\n",
        "\n",
        "    def _validate(self, value: str):\n",
        "        if self.pii_entities is not None:\n",
        "            analysis = self.analyzer.analyze(\n",
        "                value, entities=self.pii_entities, language='en')\n",
        "        else:\n",
        "            analysis = self.analyzer.analyze(\n",
        "                value, language='en')\n",
        "\n",
        "        if len(analysis):\n",
        "            result = {'label':[a.entity_type for a in analysis],\n",
        "                      'score':[a.score for a in analysis]}\n",
        "\n",
        "            new_value = self.anonymizer.anonymize(\n",
        "                text=value, analyzer_results=analysis)\n",
        "\n",
        "            return FailResult(\n",
        "                error_message = json.dumps(result),\n",
        "                fix_value=\"Privacy is a big deal! Let's keep personal info \"\n",
        "                          \"out of our chat. \"\n",
        "                          \"Feel free to rephrase your question. \")\n",
        "                # Decision point: Do we want to redact user input?\n",
        "                # if so, then `fix_value=new_value.text`\n",
        "        else:\n",
        "            return PassResult(\n",
        "                value_override=json.dumps({'label':['N/A'], 'score':[0]}))"
      ],
      "metadata": {
        "id": "yg2Ymn2QPiyg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Test and Demo"
      ],
      "metadata": {
        "id": "oodlcyNQKok4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLKBTU8qwdl4",
        "outputId": "e881add0-c816-4b94-bbbd-ef127195e607"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Result: fail, Details: {'label': ['PERSON', 'PHONE_NUMBER'], 'score': [0.85, 0.75]}, Bot Reponse: Privacy is a big deal! Let's keep personal info out of our chat. Feel free to rephrase your question. \n",
            "Validation Result: pass, Details: {'label': ['N/A'], 'score': [0]}\n"
          ]
        }
      ],
      "source": [
        "# Scope\n",
        "pii_entities = [\n",
        "    \"PERSON\", \"FIRST_NAME\", \"LAST_NAME\", \"EMAIL_ADDRESS\", \"PHONE_NUMBER\",\n",
        "    \"LOCATION\", \"CITY\", \"STATE_OR_PROVINCE\", \"COUNTRY\", \"ZIP_CODE\",\n",
        "    \"CREDIT_CARD\", \"IN_PAN\"]\n",
        "\n",
        "# Instantiation\n",
        "pii_gr = PIIGuardrail(\n",
        "    analyzer=analyzer, anonymizer=anonymizer, pii_entities=pii_entities)\n",
        "\n",
        "# Demo\n",
        "demo1 = pii_gr._validate(\"My Name is Colin and my number is 0405 567 789, I need to know ....\")\n",
        "demo2 = pii_gr._validate(\"Hey I just want to know more about the minimum payment amount ...\")\n",
        "\n",
        "# Print validation\n",
        "_ = get_result(demo1)\n",
        "_ = get_result(demo2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix"
      ],
      "metadata": {
        "id": "lHkJRt4hWwfO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFnL_2Qdwdl5",
        "outputId": "1bda565d-e86f-459b-f10d-5588a21ad2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hullucination': __main__.HallucinationGuardrail,\n",
              " 'toxicity': __main__.ToxicityGuardrail,\n",
              " 'english_input': __main__.EnglishInputGuardrail,\n",
              " 'topic': __main__.TopicGuardrail,\n",
              " 'competitor': __main__.CompetitorGuardrail,\n",
              " 'PII': __main__.PIIGuardrail}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# How to check all registered GRs\n",
        "validator_base.validators_registry"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}